{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_1 = pd.read_csv('pdb_data_no_dups.csv')\n",
    "df_2 = pd.read_csv('pdb_data_seq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structureId</th>\n",
       "      <th>classification</th>\n",
       "      <th>experimentalTechnique</th>\n",
       "      <th>macromoleculeType</th>\n",
       "      <th>residueCount</th>\n",
       "      <th>resolution</th>\n",
       "      <th>structureMolecularWeight</th>\n",
       "      <th>crystallizationMethod</th>\n",
       "      <th>crystallizationTempK</th>\n",
       "      <th>densityMatthews</th>\n",
       "      <th>densityPercentSol</th>\n",
       "      <th>pdbxDetails</th>\n",
       "      <th>phValue</th>\n",
       "      <th>publicationYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100D</td>\n",
       "      <td>DNA-RNA HYBRID</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>DNA/RNA Hybrid</td>\n",
       "      <td>20</td>\n",
       "      <td>1.90</td>\n",
       "      <td>6360.30</td>\n",
       "      <td>VAPOR DIFFUSION, HANGING DROP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.78</td>\n",
       "      <td>30.89</td>\n",
       "      <td>pH 7.00, VAPOR DIFFUSION, HANGING DROP</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101D</td>\n",
       "      <td>DNA</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>DNA</td>\n",
       "      <td>24</td>\n",
       "      <td>2.25</td>\n",
       "      <td>7939.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.00</td>\n",
       "      <td>38.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101M</td>\n",
       "      <td>OXYGEN TRANSPORT</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>Protein</td>\n",
       "      <td>154</td>\n",
       "      <td>2.07</td>\n",
       "      <td>18112.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.09</td>\n",
       "      <td>60.20</td>\n",
       "      <td>3.0 M AMMONIUM SULFATE, 20 MM TRIS, 1MM EDTA, ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102D</td>\n",
       "      <td>DNA</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>DNA</td>\n",
       "      <td>24</td>\n",
       "      <td>2.20</td>\n",
       "      <td>7637.17</td>\n",
       "      <td>VAPOR DIFFUSION, SITTING DROP</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>46.06</td>\n",
       "      <td>pH 7.00, VAPOR DIFFUSION, SITTING DROP, temper...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102L</td>\n",
       "      <td>HYDROLASE(O-GLYCOSYL)</td>\n",
       "      <td>X-RAY DIFFRACTION</td>\n",
       "      <td>Protein</td>\n",
       "      <td>165</td>\n",
       "      <td>1.74</td>\n",
       "      <td>18926.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>55.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  structureId         classification experimentalTechnique macromoleculeType  \\\n",
       "0        100D         DNA-RNA HYBRID     X-RAY DIFFRACTION    DNA/RNA Hybrid   \n",
       "1        101D                    DNA     X-RAY DIFFRACTION               DNA   \n",
       "2        101M       OXYGEN TRANSPORT     X-RAY DIFFRACTION           Protein   \n",
       "3        102D                    DNA     X-RAY DIFFRACTION               DNA   \n",
       "4        102L  HYDROLASE(O-GLYCOSYL)     X-RAY DIFFRACTION           Protein   \n",
       "\n",
       "   residueCount  resolution  structureMolecularWeight  \\\n",
       "0            20        1.90                   6360.30   \n",
       "1            24        2.25                   7939.35   \n",
       "2           154        2.07                  18112.80   \n",
       "3            24        2.20                   7637.17   \n",
       "4           165        1.74                  18926.61   \n",
       "\n",
       "           crystallizationMethod  crystallizationTempK  densityMatthews  \\\n",
       "0  VAPOR DIFFUSION, HANGING DROP                   NaN             1.78   \n",
       "1                            NaN                   NaN             2.00   \n",
       "2                            NaN                   NaN             3.09   \n",
       "3  VAPOR DIFFUSION, SITTING DROP                 277.0             2.28   \n",
       "4                            NaN                   NaN             2.75   \n",
       "\n",
       "   densityPercentSol                                        pdbxDetails  \\\n",
       "0              30.89             pH 7.00, VAPOR DIFFUSION, HANGING DROP   \n",
       "1              38.45                                                NaN   \n",
       "2              60.20  3.0 M AMMONIUM SULFATE, 20 MM TRIS, 1MM EDTA, ...   \n",
       "3              46.06  pH 7.00, VAPOR DIFFUSION, SITTING DROP, temper...   \n",
       "4              55.28                                                NaN   \n",
       "\n",
       "   phValue  publicationYear  \n",
       "0      7.0           1994.0  \n",
       "1      NaN           1995.0  \n",
       "2      9.0           1999.0  \n",
       "3      7.0           1995.0  \n",
       "4      NaN           1993.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structureId</th>\n",
       "      <th>chainId</th>\n",
       "      <th>sequence</th>\n",
       "      <th>residueCount</th>\n",
       "      <th>macromoleculeType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100D</td>\n",
       "      <td>A</td>\n",
       "      <td>CCGGCGCCGG</td>\n",
       "      <td>20</td>\n",
       "      <td>DNA/RNA Hybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100D</td>\n",
       "      <td>B</td>\n",
       "      <td>CCGGCGCCGG</td>\n",
       "      <td>20</td>\n",
       "      <td>DNA/RNA Hybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101D</td>\n",
       "      <td>A</td>\n",
       "      <td>CGCGAATTCGCG</td>\n",
       "      <td>24</td>\n",
       "      <td>DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101D</td>\n",
       "      <td>B</td>\n",
       "      <td>CGCGAATTCGCG</td>\n",
       "      <td>24</td>\n",
       "      <td>DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101M</td>\n",
       "      <td>A</td>\n",
       "      <td>MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...</td>\n",
       "      <td>154</td>\n",
       "      <td>Protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  structureId chainId                                           sequence  \\\n",
       "0        100D       A                                         CCGGCGCCGG   \n",
       "1        100D       B                                         CCGGCGCCGG   \n",
       "2        101D       A                                       CGCGAATTCGCG   \n",
       "3        101D       B                                       CGCGAATTCGCG   \n",
       "4        101M       A  MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...   \n",
       "\n",
       "   residueCount macromoleculeType  \n",
       "0            20    DNA/RNA Hybrid  \n",
       "1            20    DNA/RNA Hybrid  \n",
       "2            24               DNA  \n",
       "3            24               DNA  \n",
       "4           154           Protein  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df_info, df_seqs):\n",
    "    '''\n",
    "    Preprocess csv protein sequence and information data\n",
    "    Input:\n",
    "    df_info: pd dataframe from info csv\n",
    "    df_seqs: pd dataframe from sequence csv\n",
    "    Output:\n",
    "    df_new: joint preprocessed pd dataframe\n",
    "    '''\n",
    "    \n",
    "    # remove unwanted features\n",
    "    df_1= df_info.drop(['experimentalTechnique', 'residueCount', 'resolution',\n",
    "       'structureMolecularWeight', 'crystallizationMethod',\n",
    "       'crystallizationTempK', 'densityMatthews', 'densityPercentSol',\n",
    "       'pdbxDetails', 'phValue', 'publicationYear'], axis=1) \n",
    "    df_2= df_seqs.drop(['chainId', 'residueCount'], axis=1) \n",
    "    \n",
    "    # drop duplicated based on structureId\n",
    "    df1 = df_1.drop_duplicates(subset='structureId', keep='first',inplace=False)\n",
    "    df2 = df_2.drop_duplicates(subset='structureId', keep='first',inplace=False)\n",
    "    \n",
    "    # join two dataframes\n",
    "    df = pd.merge(df1, df2, left_on='structureId', right_on='structureId')\n",
    "    \n",
    "    # select only protein sequences\n",
    "    df_select= df[df['macromoleculeType_x']=='Protein']\n",
    "    \n",
    "    # remove feature indicating it is protein sequences\n",
    "    df_select = df_select.drop(['macromoleculeType_x', 'macromoleculeType_y'], axis=1) \n",
    "    \n",
    "    \n",
    "    # remove duplicate sequences and NA values\n",
    "    df_new = df_select.drop_duplicates(subset='sequence', keep='first',inplace=False)\n",
    "    df_new = df_new.dropna(how='any')\n",
    "    \n",
    "    # rename structureId to Id\n",
    "    df_new.columns = ['Id', 'classification',  'sequence']\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_df(df, top_value = 10):\n",
    "    '''\n",
    "    Select classes with most number of sequences\n",
    "    Input:\n",
    "    df: pd dataframe with classification and sequences\n",
    "    top_value: number of classes to be selected \n",
    "    Output:\n",
    "    df_new: pd dataframe contains only the selected classes\n",
    "    '''\n",
    "    # count number of sequences in each classification\n",
    "    count = df.groupby('classification')['Id'].nunique()\n",
    "    sort_count = count.sort_values() # sort values\n",
    "    classes = [i for i in sort_count.index if 'UNKNOWN' not in i] # remove unknown classes\n",
    "    classes = classes[-top_value:] # pick top value classes\n",
    "    print(\"Following classes are selected: \")\n",
    "    print(classes)\n",
    "    # selected rows in df belongs to the selected classes\n",
    "    df_new = df[[c in classes for c in df.classification]]\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following classes are selected: \n",
      "['VIRAL PROTEIN', 'ISOMERASE', 'TRANSPORT PROTEIN', 'SIGNALING PROTEIN', 'TRANSCRIPTION', 'LYASE', 'IMMUNE SYSTEM', 'OXIDOREDUCTASE', 'TRANSFERASE', 'HYDROLASE']\n"
     ]
    }
   ],
   "source": [
    "df = data_preprocess(df_1, df_2)\n",
    "top_value = 10\n",
    "df_new = select_df(df,top_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>classification</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101M</td>\n",
       "      <td>OXYGEN TRANSPORT</td>\n",
       "      <td>MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102L</td>\n",
       "      <td>HYDROLASE(O-GLYCOSYL)</td>\n",
       "      <td>MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAAKSE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102M</td>\n",
       "      <td>OXYGEN TRANSPORT</td>\n",
       "      <td>MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>103L</td>\n",
       "      <td>HYDROLASE(O-GLYCOSYL)</td>\n",
       "      <td>MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNSLDAAK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>104L</td>\n",
       "      <td>HYDROLASE(O-GLYCOSYL)</td>\n",
       "      <td>MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSAA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id         classification  \\\n",
       "2   101M       OXYGEN TRANSPORT   \n",
       "4   102L  HYDROLASE(O-GLYCOSYL)   \n",
       "5   102M       OXYGEN TRANSPORT   \n",
       "7   103L  HYDROLASE(O-GLYCOSYL)   \n",
       "10  104L  HYDROLASE(O-GLYCOSYL)   \n",
       "\n",
       "                                             sequence  \n",
       "2   MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...  \n",
       "4   MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAAKSE...  \n",
       "5   MVLSEGEWQLVLHVWAKVEADVAGHGQDILIRLFKSHPETLEKFDR...  \n",
       "7   MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNSLDAAK...  \n",
       "10  MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSAA...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>classification</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>117E</td>\n",
       "      <td>HYDROLASE</td>\n",
       "      <td>TYTTRQIGAKNTLEYKVYIEKDGKPVSAFHDIPLYADKENNIFNMV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11BA</td>\n",
       "      <td>HYDROLASE</td>\n",
       "      <td>KESAAAKFERQHMDSGNSPSSSSNYCNLMMCCRKMTQGKCKPVNTF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>11GS</td>\n",
       "      <td>TRANSFERASE</td>\n",
       "      <td>MPPYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>177L</td>\n",
       "      <td>HYDROLASE</td>\n",
       "      <td>MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSEL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>17GS</td>\n",
       "      <td>TRANSFERASE</td>\n",
       "      <td>MPPYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id classification                                           sequence\n",
       "44   117E      HYDROLASE  TYTTRQIGAKNTLEYKVYIEKDGKPVSAFHDIPLYADKENNIFNMV...\n",
       "50   11BA      HYDROLASE  KESAAAKFERQHMDSGNSPSSSSNYCNLMMCCRKMTQGKCKPVNTF...\n",
       "52   11GS    TRANSFERASE  MPPYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKA...\n",
       "170  177L      HYDROLASE  MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSEL...\n",
       "175  17GS    TRANSFERASE  MPPYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKA..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate X Y data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "seqs = df_new.sequence.values\n",
    "lengths = [len(s) for s in seqs]\n",
    "\n",
    "# maximum length of sequence, discard everything else\n",
    "max_length = 256\n",
    "\n",
    "#create and fit tokenizer\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(seqs)\n",
    "\n",
    "#represent input data as word rank number sequences\n",
    "X = tokenizer.texts_to_sequences(seqs)\n",
    "X = sequence.pad_sequences(X, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Transform labels to one-hot\n",
    "lb = LabelBinarizer()\n",
    "Y = lb.fit_transform(df_new.classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38901, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38901, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create top 3 accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "top3_acc = functools.partial(top_k_categorical_accuracy, k=3)\n",
    "top3_acc.__name__ = 'top3_acc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and complie model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 256, 20)           520       \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 254, 512)          31232     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_11 (CuDNNLSTM)    (None, 256)               788480    \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 854,418\n",
      "Trainable params: 854,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, LSTM, Dense, Dropout\n",
    "from keras import backend\n",
    "if len(backend.tensorflow_backend._get_available_gpus()) > 0:\n",
    "    from keras.layers import CuDNNLSTM as LSTM \n",
    "\n",
    "# Hyperparameters\n",
    "dp = 0.5\n",
    "embedding_dim = 20\n",
    "l2_reg = 10e-3\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, embedding_dim, input_length=max_length))\n",
    "model.add(Conv1D(filters=512, kernel_size=3, padding='valid', activation='relu'))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(dp))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(dp))\n",
    "model.add(Dense(top_value, activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics=['accuracy',top3_acc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31120 samples, validate on 7781 samples\n",
      "Epoch 1/50\n",
      "31120/31120 [==============================] - 12s 372us/step - loss: 2.0483 - acc: 0.2705 - top3_acc: 0.6447 - val_loss: 1.9744 - val_acc: 0.2984 - val_top3_acc: 0.6716\n",
      "Epoch 2/50\n",
      "31120/31120 [==============================] - 9s 285us/step - loss: 1.9683 - acc: 0.2910 - top3_acc: 0.6725 - val_loss: 1.8836 - val_acc: 0.3033 - val_top3_acc: 0.6930\n",
      "Epoch 3/50\n",
      "31120/31120 [==============================] - 9s 291us/step - loss: 1.9001 - acc: 0.2987 - top3_acc: 0.6856 - val_loss: 1.8225 - val_acc: 0.3308 - val_top3_acc: 0.7026\n",
      "Epoch 4/50\n",
      "31120/31120 [==============================] - 9s 284us/step - loss: 1.8182 - acc: 0.3263 - top3_acc: 0.7059 - val_loss: 1.7845 - val_acc: 0.3335 - val_top3_acc: 0.7182\n",
      "Epoch 5/50\n",
      "31120/31120 [==============================] - 9s 302us/step - loss: 1.7733 - acc: 0.3486 - top3_acc: 0.7157 - val_loss: 1.7231 - val_acc: 0.3584 - val_top3_acc: 0.7290\n",
      "Epoch 6/50\n",
      "31120/31120 [==============================] - 9s 291us/step - loss: 1.7965 - acc: 0.3415 - top3_acc: 0.7073 - val_loss: 1.7114 - val_acc: 0.3628 - val_top3_acc: 0.7275\n",
      "Epoch 7/50\n",
      "31120/31120 [==============================] - 9s 291us/step - loss: 1.7069 - acc: 0.3794 - top3_acc: 0.7272 - val_loss: 1.6573 - val_acc: 0.3938 - val_top3_acc: 0.7378\n",
      "Epoch 8/50\n",
      "31120/31120 [==============================] - 9s 287us/step - loss: 1.6540 - acc: 0.4039 - top3_acc: 0.7402 - val_loss: 1.6601 - val_acc: 0.3940 - val_top3_acc: 0.7336\n",
      "Epoch 9/50\n",
      "31120/31120 [==============================] - 9s 291us/step - loss: 1.6252 - acc: 0.4177 - top3_acc: 0.7425 - val_loss: 1.6053 - val_acc: 0.4179 - val_top3_acc: 0.7490\n",
      "Epoch 10/50\n",
      "31120/31120 [==============================] - 9s 291us/step - loss: 1.5807 - acc: 0.4357 - top3_acc: 0.7524 - val_loss: 1.5543 - val_acc: 0.4418 - val_top3_acc: 0.7538\n",
      "Epoch 11/50\n",
      "31120/31120 [==============================] - 9s 287us/step - loss: 1.5367 - acc: 0.4514 - top3_acc: 0.7596 - val_loss: 1.5408 - val_acc: 0.4523 - val_top3_acc: 0.7513\n",
      "Epoch 12/50\n",
      "31120/31120 [==============================] - 9s 294us/step - loss: 1.4888 - acc: 0.4711 - top3_acc: 0.7663 - val_loss: 1.5086 - val_acc: 0.4643 - val_top3_acc: 0.7635\n",
      "Epoch 13/50\n",
      "31120/31120 [==============================] - 9s 293us/step - loss: 1.4390 - acc: 0.4924 - top3_acc: 0.7784 - val_loss: 1.4726 - val_acc: 0.4807 - val_top3_acc: 0.7683\n",
      "Epoch 14/50\n",
      "31120/31120 [==============================] - 9s 296us/step - loss: 1.3849 - acc: 0.5110 - top3_acc: 0.7851 - val_loss: 1.4361 - val_acc: 0.5056 - val_top3_acc: 0.7796\n",
      "Epoch 15/50\n",
      "31120/31120 [==============================] - 9s 289us/step - loss: 1.3327 - acc: 0.5342 - top3_acc: 0.7947 - val_loss: 1.3900 - val_acc: 0.5156 - val_top3_acc: 0.7924\n",
      "Epoch 16/50\n",
      "31120/31120 [==============================] - 9s 296us/step - loss: 1.2767 - acc: 0.5568 - top3_acc: 0.8043 - val_loss: 1.3592 - val_acc: 0.5325 - val_top3_acc: 0.8004\n",
      "Epoch 17/50\n",
      "31120/31120 [==============================] - 9s 285us/step - loss: 1.2212 - acc: 0.5793 - top3_acc: 0.8188 - val_loss: 1.3988 - val_acc: 0.5236 - val_top3_acc: 0.7913\n",
      "Epoch 18/50\n",
      "31120/31120 [==============================] - 9s 286us/step - loss: 1.1685 - acc: 0.5974 - top3_acc: 0.8269 - val_loss: 1.3404 - val_acc: 0.5560 - val_top3_acc: 0.8002\n",
      "Epoch 19/50\n",
      "31120/31120 [==============================] - 9s 286us/step - loss: 1.1173 - acc: 0.6175 - top3_acc: 0.8395 - val_loss: 1.3014 - val_acc: 0.5677 - val_top3_acc: 0.8108\n",
      "Epoch 20/50\n",
      "31120/31120 [==============================] - 9s 291us/step - loss: 1.0531 - acc: 0.6397 - top3_acc: 0.8508 - val_loss: 1.2687 - val_acc: 0.5817 - val_top3_acc: 0.8143\n",
      "Epoch 21/50\n",
      "31120/31120 [==============================] - 9s 286us/step - loss: 0.9811 - acc: 0.6654 - top3_acc: 0.8645 - val_loss: 1.2611 - val_acc: 0.5952 - val_top3_acc: 0.8152\n",
      "Epoch 22/50\n",
      "31120/31120 [==============================] - 9s 291us/step - loss: 0.9293 - acc: 0.6875 - top3_acc: 0.8737 - val_loss: 1.2705 - val_acc: 0.5948 - val_top3_acc: 0.8202\n",
      "Epoch 23/50\n",
      "31120/31120 [==============================] - 9s 288us/step - loss: 0.8686 - acc: 0.7091 - top3_acc: 0.8825 - val_loss: 1.2721 - val_acc: 0.6177 - val_top3_acc: 0.8230\n",
      "Epoch 24/50\n",
      "31120/31120 [==============================] - 9s 295us/step - loss: 0.8226 - acc: 0.7247 - top3_acc: 0.8961 - val_loss: 1.2961 - val_acc: 0.6188 - val_top3_acc: 0.8203\n",
      "Epoch 25/50\n",
      "31120/31120 [==============================] - 9s 288us/step - loss: 0.7650 - acc: 0.7439 - top3_acc: 0.9053 - val_loss: 1.2767 - val_acc: 0.6273 - val_top3_acc: 0.8293\n",
      "Epoch 26/50\n",
      "31120/31120 [==============================] - 9s 292us/step - loss: 0.7125 - acc: 0.7645 - top3_acc: 0.9139 - val_loss: 1.3201 - val_acc: 0.6254 - val_top3_acc: 0.8316\n",
      "Epoch 27/50\n",
      "31120/31120 [==============================] - 9s 288us/step - loss: 0.6780 - acc: 0.7756 - top3_acc: 0.9193 - val_loss: 1.3269 - val_acc: 0.6340 - val_top3_acc: 0.8244\n",
      "Epoch 28/50\n",
      "31120/31120 [==============================] - 9s 288us/step - loss: 0.6386 - acc: 0.7887 - top3_acc: 0.9268 - val_loss: 1.4113 - val_acc: 0.6345 - val_top3_acc: 0.8214\n",
      "Epoch 29/50\n",
      "31120/31120 [==============================] - 9s 290us/step - loss: 0.6027 - acc: 0.8027 - top3_acc: 0.9330 - val_loss: 1.3087 - val_acc: 0.6454 - val_top3_acc: 0.8243\n",
      "Epoch 30/50\n",
      "18560/31120 [================>.............] - ETA: 3s - loss: 0.5458 - acc: 0.8237 - top3_acc: 0.9420"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('categorical_accuracy')\n",
    "ax[1].plot(hist.epoch, hist.history[\"acc\"], label=\"Train categorical_accuracy\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_acc\"], label=\"Validation categorical_accuracy\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "print(\"Train accuracy = \" + str(accuracy_score(np.argmax(y_train, axis=1), np.argmax(train_pred, axis=1))))\n",
    "print(\"Test accuracy = \" + str(accuracy_score(np.argmax(y_test, axis=1), np.argmax(test_pred, axis=1))))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(test_pred, axis=1))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix', fontsize = 16)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(lb.classes_))\n",
    "plt.xticks(tick_marks, lb.classes_, rotation=90)\n",
    "plt.yticks(tick_marks, lb.classes_)\n",
    "plt.ylabel('True label',fontsize = 16)\n",
    "plt.xlabel('Predicted label',fontsize = 16)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(test_pred, axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import regularizers\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 20\n",
    "dp = 0.5\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, embedding_dim, input_length=max_length))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='valid', activation='relu'))\n",
    "model.add(Dropout(dp))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=2, padding='valid', activation='relu'))\n",
    "model.add(Dropout(dp))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(dp))\n",
    "model.add(Dense(top_value, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',top3_acc])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist2.epoch, hist2.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist2.epoch, hist2.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('categorical_accuracy')\n",
    "ax[1].plot(hist2.epoch, hist2.history[\"acc\"], label=\"Train categorical_accuracy\")\n",
    "ax[1].plot(hist2.epoch, hist2.history[\"val_acc\"], label=\"Validation categorical_accuracy\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "print(\"train-acc = \" + str(accuracy_score(np.argmax(y_train, axis=1), np.argmax(train_pred, axis=1))))\n",
    "print(\"test-acc = \" + str(accuracy_score(np.argmax(y_test, axis=1), np.argmax(test_pred, axis=1))))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(test_pred, axis=1))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix',fontsize = 16)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(lb.classes_))\n",
    "plt.xticks(tick_marks, lb.classes_, rotation=90)\n",
    "plt.yticks(tick_marks, lb.classes_)\n",
    "plt.ylabel('True label',fontsize = 16)\n",
    "plt.xlabel('Predicted label',fontsize = 16)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(test_pred, axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 256, 8)            208       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 253, 64)           2112      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 253, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 126, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 125, 32)           4128      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 125, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                127040    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 134,138\n",
      "Trainable params: 134,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import regularizers\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 8\n",
    "dp = 0.2\n",
    "l2_reg = 0 #10e-3\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, embedding_dim, input_length=max_length))\n",
    "#model.add(BatchNormalization(input_shape = (max_length,1)))\n",
    "model.add(Conv1D(filters=64, kernel_size=4, padding='valid', activation='relu'))\n",
    "model.add(Dropout(dp))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=2, padding='valid', activation='relu'))\n",
    "model.add(Dropout(dp))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu',kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "\n",
    "model.add(Dense(top_value, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',top3_acc])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
